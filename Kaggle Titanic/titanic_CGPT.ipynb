{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S', 'Embarked_nan', 'Title_Master',\n",
      "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer',\n",
      "       'Title_Royalty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the train data set\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Can simplify the Titles with this dictionary:\n",
    "Title_Dictionary = {\"Capt\"  : \"Officer\", \n",
    "                    \"Col\"   : \"Officer\",\n",
    "                    \"Major\" : \"Officer\",\n",
    "                    \"Dr\"    : \"Officer\", \n",
    "                    \"Rev\"   : \"Officer\", \n",
    "                    \"Don\"   : \"Royalty\", \n",
    "                    \"Sir\"   : \"Royalty\", \n",
    "                    \"Jonkheer\": \"Royalty\",\n",
    "                    \"the Countess\":\"Royalty\", \n",
    "                    \"Mr\"    : \"Mr\", \n",
    "                    \"Mme\"   : \"Mrs\", \n",
    "                    \"Mrs\"   : \"Mrs\", \n",
    "                    \"Ms\"    : \"Miss\", \n",
    "                    \"Miss\"  : \"Miss\", \n",
    "                    \"Mlle\"  : \"Miss\", \n",
    "                    \"Master\" : \"Master\", \n",
    "                    \"Lady\"  : \"Royalty\" \n",
    "                    }\n",
    "    \n",
    "# adding summarized \"Title\" column to data\n",
    "data[\"Title\"] = data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "data[\"Title\"] = data[\"Title\"].map(Title_Dictionary)\n",
    "# print(data[\"Title\"].value_counts())\n",
    "\n",
    "for i in ('Sex','Embarked', 'Title'):\n",
    "    # Create a one-hot encoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Encode the \"Sex\" column\n",
    "    encoder.fit(data[[i]])\n",
    "    sex_encoded = encoder.transform(data[[i]])\n",
    "    sex_encoded_df = pd.DataFrame(sex_encoded.toarray(), columns=encoder.get_feature_names_out([i]))\n",
    "\n",
    "    # Join the encoded column to the original dataframe\n",
    "    data = pd.concat([data, sex_encoded_df], axis=1)\n",
    "\n",
    "    # Drop the original \"Sex\" column\n",
    "    data = data.drop(columns=[i])\n",
    "\n",
    "# # Create a one-hot encoder\n",
    "# encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# # Encode the \"Sex\" column\n",
    "# encoder.fit(data[['Sex']])\n",
    "# sex_encoded = encoder.transform(data[['Sex']])\n",
    "\n",
    "# # Get the original categories\n",
    "# original_categories = encoder.categories_[0]\n",
    "\n",
    "# # Get the new column names\n",
    "# new_columns = encoder.get_feature_names_out(['Sex'])\n",
    "\n",
    "# # Map the new column names with the original categories\n",
    "# new_columns = [f\"{new_columns[i]}_{original_categories[i]}\" for i in range(len(original_categories))]\n",
    "# sex_encoded_df = pd.DataFrame(sex_encoded.toarray(), columns=new_columns)\n",
    "\n",
    "# # Join the encoded column to the original dataframe\n",
    "# data = pd.concat([data, sex_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "print(data.columns)\n",
    "# Drop the original \"Sex\" column and other non-numerical columns\n",
    "# train = train.drop(columns=[\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female',\n",
       "       'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Embarked_nan',\n",
       "       'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer',\n",
       "       'Title_Royalty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform an 80/20 train test split\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train = train.drop(columns=[\"Name\", \"Ticket\", \"Cabin\"]).dropna()\n",
    "\n",
    "# Split the data into y_train and x_train\n",
    "y_train = train[\"Survived\"]\n",
    "x_train = train.drop(columns=[\"Survived\"])\n",
    "\n",
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Sex_female_female',\n",
      "       'Sex_male_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Load the train data set\n",
    "# data = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "# # for i in ('Sex'):\n",
    "# #     # Create a one-hot encoder\n",
    "# #     encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# #     # Encode the current column\n",
    "# #     encoder.fit(train[[i]])\n",
    "# #     sex_encoded = encoder.transform(train[[i]])\n",
    "# #     sex_encoded_df = pd.DataFrame(sex_encoded.toarray(), columns=encoder.get_feature_names_out([i]))\n",
    "\n",
    "# #     # Join the encoded column to the original dataframe\n",
    "# #     train = pd.concat([train, sex_encoded_df], axis=1)\n",
    "\n",
    "# #     # Drop the original column\n",
    "# #     train = train.drop(columns=[i])\n",
    "# #     # print(train.head(2))\n",
    "\n",
    "# # Create a one-hot encoder\n",
    "# encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# # Encode the \"Sex\" column\n",
    "# encoder.fit(data[['Sex']])\n",
    "# sex_encoded = encoder.transform(data[['Sex']])\n",
    "\n",
    "# # Get the original categories\n",
    "# original_categories = encoder.categories_[0]\n",
    "\n",
    "# # Get the new column names\n",
    "# new_columns = encoder.get_feature_names_out(['Sex'])\n",
    "\n",
    "# # Map the new column names with the original categories\n",
    "# new_columns = [f\"{new_columns[i]}_{original_categories[i]}\" for i in range(len(original_categories))]\n",
    "# sex_encoded_df = pd.DataFrame(sex_encoded.toarray(), columns=new_columns)\n",
    "\n",
    "# # Join the encoded column to the original dataframe\n",
    "# data = pd.concat([data, sex_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "# print(data.columns)\n",
    "# # Drop the original \"Sex\" column and other non-numerical columns\n",
    "# # train = train.drop(columns=[\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 14)\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Sex_female_female',\n",
      "       'Sex_male_male'],\n",
      "      dtype='object')\n",
      "\n",
      "(179, 14)\n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Sex_female_female',\n",
      "       'Sex_male_male'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Sex_female_female', 'Sex_male_male'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare',\n",
      "       'Sex_female_female', 'Sex_male_male'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Perform an 80/20 train test split\n",
    "# train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "# print(train.shape)\n",
    "# print(train.columns)\n",
    "# print()\n",
    "# print(test.shape)\n",
    "# print(test.columns)\n",
    "\n",
    "# train = train.drop(columns=[\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"]).dropna()\n",
    "# test = test.drop(columns=[\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"]).dropna()\n",
    "\n",
    "# # # Split the data into y_train and x_train\n",
    "# y_train = train[\"Survived\"]\n",
    "# x_train = train.drop(columns=[\"Survived\"])\n",
    "\n",
    "# y_test = test[\"Survived\"]\n",
    "# x_test = test.drop(columns=[\"Survived\"])\n",
    "\n",
    "# # x_train.columns\n",
    "# x_test.columns\n",
    "\n",
    "# # print(y_train)\n",
    "# # print(y_test)\n",
    "\n",
    "# # print(y_train.columns)\n",
    "# # print(y_test.columns)\n",
    "# print(x_train.columns)\n",
    "# print(x_test.columns)\n",
    "# # print(train.columns)\n",
    "# # print(test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Age', 'Fare', 'Sex_female_female', 'Sex_male_male'], dtype='object')\n",
      "Model accuracy: 0.7746478873239436\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model\n",
    "RF = RandomForestClassifier(random_state=1)\n",
    "\n",
    "\n",
    "# Use RFE (Recursive Factor Elimination) to select the top 4 features\n",
    "my_RF_model = RFE(estimator=RF, n_features_to_select=5)\n",
    "my_RF_model.fit(x_train, y_train)\n",
    "\n",
    "# Print the selected features\n",
    "print(x_train.columns[my_RF_model.support_])\n",
    "\n",
    "# Fit the model to the x_train and y_train data\n",
    "my_RF_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions for the test data\n",
    "y_test_pred = my_RF_model.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "# Measure the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8841f7bafa9d104dbee62c6cf5f62fae5061e5f4a5ff02b7a6a5ce4bc4f60264"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
