{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Age', 'SibSp', 'Parch',\n",
      "       'Ticket', 'Fare', 'Cabin', 'Sex_female', 'Sex_male', 'Embarked_C',\n",
      "       'Embarked_Q', 'Embarked_S', 'Embarked_nan', 'Title_Master',\n",
      "       'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer',\n",
      "       'Title_Royalty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the train data set\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Can simplify the Titles with this dictionary:\n",
    "Title_Dictionary = {\"Capt\"  : \"Officer\", \n",
    "                    \"Col\"   : \"Officer\",\n",
    "                    \"Major\" : \"Officer\",\n",
    "                    \"Dr\"    : \"Officer\", \n",
    "                    \"Rev\"   : \"Officer\", \n",
    "                    \"Don\"   : \"Royalty\", \n",
    "                    \"Sir\"   : \"Royalty\", \n",
    "                    \"Jonkheer\": \"Royalty\",\n",
    "                    \"the Countess\":\"Royalty\", \n",
    "                    \"Mr\"    : \"Mr\", \n",
    "                    \"Mme\"   : \"Mrs\", \n",
    "                    \"Mrs\"   : \"Mrs\", \n",
    "                    \"Ms\"    : \"Miss\", \n",
    "                    \"Miss\"  : \"Miss\", \n",
    "                    \"Mlle\"  : \"Miss\", \n",
    "                    \"Master\" : \"Master\", \n",
    "                    \"Lady\"  : \"Royalty\" \n",
    "                    }\n",
    "    \n",
    "# adding summarized \"Title\" column to data\n",
    "data[\"Title\"] = data['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "data[\"Title\"] = data[\"Title\"].map(Title_Dictionary)\n",
    "# print(data[\"Title\"].value_counts())\n",
    "\n",
    "for i in ('Sex','Embarked', 'Title'):\n",
    "    # Create a one-hot encoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Encode the \"Sex\" column\n",
    "    encoder.fit(data[[i]])\n",
    "    sex_encoded = encoder.transform(data[[i]])\n",
    "    sex_encoded_df = pd.DataFrame(sex_encoded.toarray(), columns=encoder.get_feature_names_out([i]))\n",
    "\n",
    "    # Join the encoded column to the original dataframe\n",
    "    data = pd.concat([data, sex_encoded_df], axis=1)\n",
    "\n",
    "    # Drop the original \"Sex\" column\n",
    "    data = data.drop(columns=[i])\n",
    "\n",
    "# # Create a one-hot encoder\n",
    "# encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "# # Encode the \"Sex\" column\n",
    "# encoder.fit(data[['Sex']])\n",
    "# sex_encoded = encoder.transform(data[['Sex']])\n",
    "# # Get the original categories\n",
    "# original_categories = encoder.categories_[0]\n",
    "# # Get the new column names\n",
    "# new_columns = encoder.get_feature_names_out(['Sex'])\n",
    "# # Map the new column names with the original categories\n",
    "# new_columns = [f\"{new_columns[i]}_{original_categories[i]}\" for i in range(len(original_categories))]\n",
    "# sex_encoded_df = pd.DataFrame(sex_encoded.toarray(), columns=new_columns)\n",
    "# # Join the encoded column to the original dataframe\n",
    "# data = pd.concat([data, sex_encoded_df], axis=1)\n",
    "\n",
    "\n",
    "print(data.columns)\n",
    "# Drop the original \"Sex\" column and other non-numerical columns\n",
    "# train = train.drop(columns=[\"Name\",\"Sex\",\"Ticket\",\"Cabin\",\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with 80/20 train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female',\n",
      "       'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Embarked_nan',\n",
      "       'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer',\n",
      "       'Title_Royalty'],\n",
      "      dtype='object')\n",
      "Index(['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex_female',\n",
      "       'Sex_male', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Embarked_nan',\n",
      "       'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Officer',\n",
      "       'Title_Royalty'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Perform an 80/20 train test split\n",
    "data = data.drop(columns=[\"Name\", \"Ticket\", \"Cabin\"]).dropna()\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data into y_train and x_train\n",
    "y_train = train[\"Survived\"]\n",
    "x_train = train.drop(columns=[\"Survived\"])\n",
    "\n",
    "y_test = test[\"Survived\"]\n",
    "x_test = test.drop(columns=[\"Survived\"])\n",
    "\n",
    "# print(y_train.columns)\n",
    "# print(y_test.columns)\n",
    "print(x_train.columns)\n",
    "print(x_test.columns)\n",
    "# print(train.columns)\n",
    "# print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Age', 'Fare', 'Sex_female', 'Title_Mr'], dtype='object')\n",
      "Model accuracy: 0.7762237762237763\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest model\n",
    "RF = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Use RFE (Recursive Factor Elimination) to select the top 4 features\n",
    "my_model = RFE(estimator=RF, n_features_to_select=5)\n",
    "my_model.fit(x_train, y_train)\n",
    "\n",
    "# Print the selected features\n",
    "print(x_train.columns[my_model.support_])\n",
    "\n",
    "# Fit the model to the x_train and y_train data\n",
    "my_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions for the test data\n",
    "y_test_pred = my_model.predict(x_test)\n",
    "\n",
    "# Measure the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pclass', 'SibSp', 'Sex_female', 'Title_Master', 'Title_Mr'], dtype='object')\n",
      "Model accuracy: 0.8041958041958042\n"
     ]
    }
   ],
   "source": [
    "# Create an XGBoost model\n",
    "xgb = XGBClassifier(random_state=1)\n",
    "\n",
    "# Use RFE (Recursive Factor Elimination) to select the top 4 features\n",
    "my_model = RFE(estimator=xgb, n_features_to_select=5)\n",
    "my_model.fit(x_train, y_train)\n",
    "\n",
    "# Print the selected features\n",
    "print(x_train.columns[my_model.support_])\n",
    "\n",
    "# Fit the model to the x_train and y_train data\n",
    "my_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions for the test data\n",
    "y_test_pred = my_model.predict(x_test)\n",
    "\n",
    "# Measure the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Model accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143 entries, 0 to 142\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   Survived  143 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.2 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 143 entries, 149 to 136\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  143 non-null    int32\n",
      " 1   Survived     143 non-null    int32\n",
      "dtypes: int32(2)\n",
      "memory usage: 2.2 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(y_test_pred, columns = ['Survived'])\n",
    "df.info()\n",
    "\n",
    "submission = pd.DataFrame({\"PassengerId\" : test['PassengerId'], \"Survived\" : y_test_pred}).astype('int32')\n",
    "submission.info()\n",
    "\n",
    "submission.to_csv(\"submission_XGB.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/Henry/Desktop/personal_projects/Kaggle Titanic/titanic_XGBoost_test.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Henry/Desktop/personal_projects/Kaggle%20Titanic/titanic_XGBoost_test.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Henry/Desktop/personal_projects/Kaggle%20Titanic/titanic_XGBoost_test.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/Henry/Desktop/personal_projects/Kaggle%20Titanic/titanic_XGBoost_test.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(np\u001b[39m.\u001b[39marray(y_test), np\u001b[39m.\u001b[39marray(y_test_pred[\u001b[39m\"\u001b[39;49m\u001b[39mSurvived\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Henry/Desktop/personal_projects/Kaggle%20Titanic/titanic_XGBoost_test.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# rmse = sqrt(mse)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/Henry/Desktop/personal_projects/Kaggle%20Titanic/titanic_XGBoost_test.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(mse)\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "# NOTE: could use this to calculate MSE & RMSE  if I had the sale price for the test data too.\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(np.array(y_test), np.array(y_test_pred[\"Survived\"]))\n",
    "# rmse = sqrt(mse)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8841f7bafa9d104dbee62c6cf5f62fae5061e5f4a5ff02b7a6a5ce4bc4f60264"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
